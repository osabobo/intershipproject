{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "BUCKET_NAME = \"de-amazon-raw-useast1-dev\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# List all buckets\n",
    "buckets_resp = s3.list_buckets()\n",
    "for bucket in buckets_resp[\"Buckets\"]:\n",
    "    print(bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "BUCKET_NAME = \"de-amazon-raw-useast1-dev\"\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# List all buckets\n",
    "# buckets_resp = s3.list_buckets()\n",
    "# for bucket in buckets_resp[\"Buckets\"]:\n",
    "#     print(bucket)\n",
    "\n",
    "# List all objects in a bucket\n",
    "response = s3.list_objects_v2(Bucket=BUCKET_NAME)\n",
    "\n",
    "# Check if 'Contents' key exists and if it's not empty\n",
    "if 'Contents' in response and response[\"Contents\"]:\n",
    "    for obj in response[\"Contents\"]:\n",
    "        print(obj)\n",
    "else:\n",
    "    print(f\"No objects found in bucket: {BUCKET_NAME}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the S3 bucket and prefix (path) where files should be uploaded\n",
    "BUCKET_NAME = 'de-amazon-raw-useast1-dev'\n",
    "PREFIX = 'amazon/raw_statistics_reference_data/'\n",
    "\n",
    "# Directory to upload from\n",
    "src_directory = '.'\n",
    "\n",
    "# Walk the local directory recursively\n",
    "for subdir, _, files in os.walk(src_directory):\n",
    "    for file in files:\n",
    "        # Check if the file ends with .json\n",
    "        if file.endswith('ext.json'):\n",
    "            # Create full local filepath\n",
    "            local_file = os.path.join(subdir, file)\n",
    "            \n",
    "            # Create full S3 key\n",
    "            s3_key = os.path.join(PREFIX, local_file[len(src_directory)+1:])\n",
    "            \n",
    "            # Upload to S3\n",
    "            s3.upload_file(local_file, BUCKET_NAME, s3_key)\n",
    "\n",
    "print(\"Upload complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative code to upload all json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative code to uplad json:\n",
    "\n",
    "# Importing necessary libraries\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the name of the bucket and the prefix\n",
    "BUCKET_NAME = 'de-on-amazon-raw-useast1-dev'\n",
    "PREFIX = 'amazon/raw_statistics_reference_data/'\n",
    "\n",
    "# Specify the directory to upload from\n",
    "src_directory = '.'\n",
    "\n",
    "# Recursively walk through the local directory\n",
    "for subdir, _, files in os.walk(src_directory):\n",
    "    for file in files:\n",
    "        # Only process files that end with .json\n",
    "        if file.endswith('.json'):\n",
    "            # Create the full local filepath\n",
    "            local_file = os.path.join(subdir, file)\n",
    "            \n",
    "            # Construct the S3 key for the file\n",
    "            s3_key = os.path.join(PREFIX, local_file[len(src_directory)+1:])\n",
    "            \n",
    "            # Upload the file to S3\n",
    "            with open(local_file, \"rb\") as f:\n",
    "                s3.upload_fileobj(\n",
    "                    f,                          # File object to be uploaded\n",
    "                    BUCKET_NAME,                # Name of the S3 bucket\n",
    "                    s3_key                      # S3 key (path) where the file will be stored\n",
    "                )\n",
    "\n",
    "print(\"Upload complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "\n",
    "# Initialize the S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the S3 bucket and prefix (path) where files should be uploaded\n",
    "BUCKET_NAME = 'de-on-amazon-raw-useast1-dev'\n",
    "PREFIX = 'amazon/raw_statistics/region=us-global/'\n",
    "\n",
    "# Directory to upload from\n",
    "src_directory = '.'\n",
    "\n",
    "# Walk the local directory recursively\n",
    "for subdir, _, files in os.walk(src_directory):\n",
    "    for file in files:\n",
    "        # Check if the file ends with .json\n",
    "        if file.endswith('.csv'):\n",
    "            # Create full local filepath\n",
    "            local_file = os.path.join(subdir, file)\n",
    "            \n",
    "            # Create full S3 key\n",
    "            s3_key = os.path.join(PREFIX, local_file[len(src_directory)+1:])\n",
    "            \n",
    "            # Upload to S3\n",
    "            s3.upload_file(local_file, BUCKET_NAME, s3_key)\n",
    "\n",
    "print(\"Upload complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative code to upload all csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative code to upload all csv:\n",
    "\n",
    "# Importing necessary libraries\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the name of the bucket and the prefix\n",
    "BUCKET_NAME = 'de-on-amazon-raw-useast1-dev'\n",
    "PREFIX = 'amazon/raw_statistics/region=us-global/'\n",
    "\n",
    "# Specify the directory to upload from\n",
    "src_directory = '.'\n",
    "\n",
    "# Recursively walk through the local directory\n",
    "for subdir, _, files in os.walk(src_directory):\n",
    "    for file in files:\n",
    "        # Only process files that end with .json\n",
    "        if file.endswith('.csv'):\n",
    "            # Create the full local filepath\n",
    "            local_file = os.path.join(subdir, file)\n",
    "            \n",
    "            # Construct the S3 key for the file\n",
    "            s3_key = os.path.join(PREFIX, local_file[len(src_directory)+1:])\n",
    "            \n",
    "            # Upload the file to S3\n",
    "            with open(local_file, \"rb\") as f:\n",
    "                s3.upload_fileobj(\n",
    "                    f,                          # File object to be uploaded\n",
    "                    BUCKET_NAME,                # Name of the S3 bucket\n",
    "                    s3_key                      # S3 key (path) where the file will be stored\n",
    "                )\n",
    "\n",
    "print(\"Upload complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define the name of the bucket and the prefix\n",
    "BUCKET_NAME = 'de-on-amazon-raw-useast1-dev'\n",
    "PREFIX = 'amazon/raw_statistics/region=us-global/'\n",
    "\n",
    "# Specify the directory where files should be downloaded\n",
    "dest_directory = './downloaded_files'\n",
    "if not os.path.exists(dest_directory):\n",
    "    os.makedirs(dest_directory)\n",
    "\n",
    "# Download all .csv files that were uploaded from the local directory to the specified S3 path\n",
    "for obj in s3.list_objects_v2(Bucket=BUCKET_NAME, Prefix=PREFIX)[\"Contents\"]:\n",
    "    local_filename = os.path.join(dest_directory, os.path.basename(obj[\"Key\"]))\n",
    "    s3.download_file(BUCKET_NAME, obj[\"Key\"], local_filename)\n",
    "\n",
    "# Explanation:\n",
    "# 1. We list all objects in the specified S3 bucket with the given prefix.\n",
    "# 2. For each object, we construct the local filename by joining the download directory and the base name of the object's key.\n",
    "# 3. We then download the object to the constructed local filename.\n",
    "\n",
    "print(\"Download complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "region = boto3.session.Session().region_name\n",
    "print(region)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
